# Migration Guide: Old vs New Embedding System

## Overview

PersonaMate a migr√© d'un syst√®me d'embedding **simple** (1 embedding par entit√©) vers un syst√®me **multi-niveaux** (embeddings global + par attribut).

## Ancien Syst√®me (Simple Embedding)

### Architecture

```
Entity ‚Üí MongoDB Document ‚Üí Summary Text ‚Üí 1 Embedding ‚Üí Qdrant
```

### Code (Ancien)

```python
from utils.rag_manager import RAGManager

rag = RAGManager.load()

# Ajout d'une entit√©
entity_id = rag.add_entity(
    entity_type="Person",
    name="Alice Johnson",
    content={
        "biography": "Alice is a data scientist...",
        "skills": ["Python", "ML"]
    }
)
# G√©n√®re 1 seul embedding global
```

### Probl√®mes

‚ùå **Un seul embedding** par entit√©
‚ùå **Perte de granularit√©** : impossible de cibler des attributs sp√©cifiques
‚ùå **Recherche impr√©cise** : m√©lange tous les attributs dans un texte
‚ùå **Dilution d'information** : attributs importants noy√©s dans le texte global
‚ùå **Pas de filtrage par attribut**

### Exemple de recherche (Ancien)

```python
# Recherche "kubernetes expert"
results = rag.search("kubernetes expert")

# Probl√®me: retourne des personnes avec "kubernetes" mentionn√©
# n'importe o√π dans leur profil, m√™me si c'est un projet pass√©
# et pas une comp√©tence principale
```

## Nouveau Syst√®me (Multi-Level Embeddings)

### Architecture

```
Entity ‚Üí MongoDB Document ‚Üí Chunks:
                             ‚îú‚îÄ Global Chunk ‚Üí Embedding (global)
                             ‚îú‚îÄ Skills Chunk ‚Üí Embedding (skills)
                             ‚îú‚îÄ Location Chunk ‚Üí Embedding (location)
                             ‚îî‚îÄ Experience Chunk ‚Üí Embedding (experience)
                                      ‚Üì
                              All embeddings ‚Üí Qdrant (with metadata)
```

### Code (Nouveau)

```python
from utils.embedding_pipeline import EmbeddingPipeline

pipeline = EmbeddingPipeline.load(use_llm_summaries=True)

# Ajout d'une entit√©
entity_id = pipeline.add_new_entity(
    entity_type="Person",
    entity_name="Alice Johnson",
    structured_data={  # NOUVEAU: Attributs structur√©s
        "name": "Alice Johnson",
        "title": "Data Scientist",
        "skills": ["Python", "ML", "TensorFlow"],
        "location": "San Francisco",
        "experience": "10 years"
    },
    text="Alice is a data scientist...",
    content={
        "biography": "...",
        "achievements": [...]
    }
)
# G√©n√®re N embeddings: 1 global + 1 par attribut/groupe
```

### Avantages

‚úÖ **Embeddings multi-niveaux** : global + attributs
‚úÖ **Granularit√© fine** : recherche cibl√©e par attribut
‚úÖ **Meilleure pr√©cision** : moins de dilution
‚úÖ **Filtrage avanc√©** : par type de chunk, attribut sp√©cifique
‚úÖ **R√©sum√©s LLM** : summaries optimis√©s (optionnel)

### Exemple de recherche (Nouveau)

```python
# Recherche globale (comme avant)
results = pipeline.search_similar_entities(
    query="kubernetes expert",
    limit=5
)

# NOUVEAU: Recherche cibl√©e sur les comp√©tences uniquement
from utils.vector_store import VectorStore

vector = VectorStore.load()
results = vector.search_chunks(
    query="kubernetes docker",
    chunk_type="attribute",
    attribute_name="skills",  # Chercher UNIQUEMENT dans skills
    limit=5
)

# R√©sultat: Retourne uniquement les personnes ayant
# kubernetes/docker dans leurs comp√©tences principales
```

## Comparison Table

| Feature | Ancien Syst√®me | Nouveau Syst√®me |
|---------|----------------|-----------------|
| **Embeddings par entit√©** | 1 (global) | N (global + attributs) |
| **Granularit√©** | Grossi√®re | Fine |
| **Recherche cibl√©e** | ‚ùå Non | ‚úÖ Oui |
| **Filtrage par attribut** | ‚ùå Non | ‚úÖ Oui |
| **R√©sum√©s LLM** | ‚ùå Non | ‚úÖ Optionnel |
| **Pr√©cision recherche** | Moyenne | √âlev√©e |
| **Flexibilit√©** | Faible | √âlev√©e |
| **Co√ªt stockage** | 1√ó | N√ó |
| **Performance recherche** | ~50ms | ~50-100ms |

## Migration Path

### Option 1: Migration Compl√®te (Recommand√©)

R√©g√©n√©rer tous les embeddings avec le nouveau syst√®me:

```python
from utils.embedding_pipeline import EmbeddingPipeline

pipeline = EmbeddingPipeline.load(use_llm_summaries=True)

# Migrer toutes les entit√©s existantes
results = pipeline.process_batch(
    force_regenerate=True  # R√©g√©n√®re tout
)

print(f"Migrated {len(results)} entities")
```

**Avantages:**
- ‚úÖ B√©n√©ficie imm√©diatement des nouveaux features
- ‚úÖ Meilleure qualit√© de recherche
- ‚úÖ Coh√©rence compl√®te

**Inconv√©nients:**
- ‚è±Ô∏è Temps de traitement pour migrer toutes les entit√©s
- üí∞ Co√ªt LLM si activ√© (~$0.00001 par entit√©)

### Option 2: Migration Progressive

Migrer uniquement les nouvelles entit√©s et laisser les anciennes:

```python
# Nouveau code utilise EmbeddingPipeline
from utils.embedding_pipeline import EmbeddingPipeline

pipeline = EmbeddingPipeline.load()

# Nouvelles entit√©s
entity_id = pipeline.add_new_entity(...)

# Anciennes entit√©s restent inchang√©es
# Elles fonctionnent toujours avec l'ancien syst√®me
```

**Avantages:**
- ‚úÖ Pas de migration bulk n√©cessaire
- ‚úÖ Coexistence des deux syst√®mes
- ‚úÖ Progressif et sans interruption

**Inconv√©nients:**
- ‚ùå Incoh√©rence entre anciennes et nouvelles entit√©s
- ‚ùå Deux APIs √† maintenir

### Option 3: Hybride (Recommand√© pour production)

Migrer progressivement les entit√©s les plus utilis√©es:

```python
from utils.embedding_pipeline import EmbeddingPipeline

pipeline = EmbeddingPipeline.load()

# Identifier les entit√©s critiques
critical_entities = [...]  # Top 100 entit√©s

# Migrer uniquement celles-ci
for entity_id in critical_entities:
    pipeline.process_entity(
        entity_id=entity_id,
        force_regenerate=True
    )

# Migrer le reste en batch async
pipeline.process_batch(
    entity_type="Person",
    force_regenerate=True
)
```

## Code Changes Required

### 1. Mise √† jour MongoDB Documents

**Ancien format:**
```json
{
  "entity_id": "person:alice",
  "entity_type": "Person",
  "entity_name": "Alice",
  "content": {
    "biography": "...",
    "skills": ["Python", "ML"]
  }
}
```

**Nouveau format:**
```json
{
  "entity_id": "person:alice",
  "entity_type": "Person",
  "entity_name": "Alice",
  "structured": {
    "name": "Alice",
    "title": "Data Scientist",
    "skills": ["Python", "ML"],
    "location": "SF"
  },
  "text": "Global description...",
  "content": {
    "biography": "...",
    "notes": "..."
  }
}
```

**Migration script:**
```python
from utils.mongo_store import MongoStore

mongo = MongoStore.load()

# Pour chaque document existant
for doc in mongo._collection.find():
    # Extraire attributs structur√©s du content
    structured = {
        "name": doc.get("entity_name"),
        "skills": doc.get("content", {}).get("skills", []),
        # ... autres attributs
    }

    # Mettre √† jour
    mongo.update_document(
        entity_id=doc["entity_id"],
        structured=structured,
        merge=True
    )
```

### 2. Mise √† jour Code Application

**Ancien code:**
```python
from utils.rag_manager import RAGManager

rag = RAGManager.load()

# Recherche
results = rag.search("data scientist", limit=5)
```

**Nouveau code:**
```python
from utils.embedding_pipeline import EmbeddingPipeline

pipeline = EmbeddingPipeline.load()

# Recherche globale (compatible)
results = pipeline.search_similar_entities(
    query="data scientist",
    limit=5
)

# OU recherche cibl√©e (nouveau feature)
from utils.vector_store import VectorStore

vector = VectorStore.load()
results = vector.search_chunks(
    query="data scientist",
    attribute_name="title",
    limit=5
)
```

## Performance Impact

### Stockage

| Syst√®me | Embeddings/Entit√© | Espace/Entit√© | Total (1000 entit√©s) |
|---------|-------------------|---------------|----------------------|
| Ancien | 1 | ~1.5 KB | 1.5 MB |
| Nouveau | ~5-10 | ~7.5-15 KB | 7.5-15 MB |

**Impact:** ~5-10√ó plus d'espace n√©cessaire

### Recherche

| Op√©ration | Ancien | Nouveau |
|-----------|--------|---------|
| Recherche simple | 50ms | 50-100ms |
| Recherche filtr√©e | N/A | 60-120ms |
| Recherche attribut | N/A | 40-80ms |

**Impact:** L√©g√®rement plus lent mais avec bien plus de pr√©cision

### G√©n√©ration

| Op√©ration | Ancien | Nouveau (sans LLM) | Nouveau (avec LLM) |
|-----------|--------|--------------------|--------------------|
| Temps/entit√© | 300ms | 500ms | 1-2s |
| Co√ªt/entit√© | $0 | $0 | ~$0.00001 |

## Backwards Compatibility

Le nouveau syst√®me est **compatible** avec l'ancien:

```python
# Ancien code fonctionne toujours
from utils.rag_manager import RAGManager

rag = RAGManager.load()
results = rag.search("query")  # ‚úÖ Fonctionne

# Nouveau code disponible en parall√®le
from utils.embedding_pipeline import EmbeddingPipeline

pipeline = EmbeddingPipeline.load()
results = pipeline.search_similar_entities("query")  # ‚úÖ Fonctionne
```

## Recommendations

### Pour Production

1. ‚úÖ **Migrer progressivement** : Option 3 (Hybride)
2. ‚úÖ **Activer LLM summaries** pour entit√©s importantes
3. ‚úÖ **Monitorer performance** et ajuster
4. ‚úÖ **Tester en staging** avant production

### Pour D√©veloppement

1. ‚úÖ **Utiliser nouveau syst√®me** imm√©diatement
2. ‚úÖ **R√©g√©n√©rer tout** avec `process_batch(force_regenerate=True)`
3. ‚úÖ **Exp√©rimenter** avec recherches cibl√©es

### Pour Tests

1. ‚úÖ **Comparer qualit√©** ancien vs nouveau
2. ‚úÖ **Mesurer pr√©cision** avec m√©triques (Recall@k, MRR)
3. ‚úÖ **Valider co√ªts** si LLM activ√©

## FAQ

### Q: Dois-je migrer imm√©diatement?

**R**: Non, les deux syst√®mes coexistent. Migrez progressivement.

### Q: Dois-je activer les r√©sum√©s LLM?

**R**: Optionnel. Testez d'abord sans, puis activez pour voir la diff√©rence. Co√ªt minimal (~$0.00001/entit√©).

### Q: Comment minimiser le co√ªt?

**R**:
- D√©sactiver LLM: `use_llm_summaries=False`
- Ou utiliser GPT-3.5 au lieu de GPT-4
- Ou traiter uniquement les entit√©s importantes

### Q: Puis-je revenir en arri√®re?

**R**: Oui, conservez les anciens embeddings et d√©sactivez le nouveau syst√®me.

### Q: Comment tester la qualit√©?

**R**: Ex√©cutez des recherches test et comparez les r√©sultats:

```python
# Comparer
old_results = rag.search("kubernetes expert", limit=10)
new_results = pipeline.search_similar_entities("kubernetes expert", limit=10)

# Analyser diff√©rences
```

## Support

- **Documentation**: [docs/embedding-pipeline.md](embedding-pipeline.md)
- **Examples**: [examples/embedding_pipeline_demo.py](../examples/embedding_pipeline_demo.py)
- **Issues**: GitHub issues
